<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE section PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="LocalDeployment">
  <title>Deploy Local (Desenvolvimento e Teste)</title>

  <para>Embora haja muitas maneiras de instalar uma plataforma HPCC Systems de
  nó único local, esta seção se concentra no uso local do Docker
  Desktop.</para>

  <sect1 id="prereq" role="nobrk">
    <title>Pré-requisitos</title>

    <para><graphic fileref="../../images/WhatYouNeed.jpg"/></para>

    <para>Todas ferramentas de terceiros devem ser 64-bits.</para>
  </sect1>

  <sect1 id="addrepo" role="nobrk">
    <title>Adicionar Repositório</title>

    <para>Para usar o helm charts do HPCC Systems, você deve adicioná-lo à
    lista de repositório do helm, conforme mostrado abaixo:</para>

    <para><programlisting>helm repo add hpcc https://hpcc-systems.github.io/helm-chart/</programlisting></para>

    <para>Expected response:</para>

    <para><programlisting>"hpcc" has been added to your repositories</programlisting></para>

    <para>To update to the latest charts:</para>

    <para><programlisting>helm repo update</programlisting></para>

    <para>You should update your local repo before any deployment to ensure
    you have the latest code available.</para>

    <para>Expected response:</para>

    <para><programlisting>Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "hpcc" chart repository
Update Complete. Happy Helming!</programlisting></para>
  </sect1>

  <sect1 id="startdefault">
    <title>Iniciar um Sistema Padrão</title>

    <para>O helm chart padrão inicia um sistema de teste simples com Dali,
    ESP, ECL CC Server, duas filas ECL Agent (modo ROXIE e hThor) e uma fila
    Thor.</para>

    <para><emphasis role="bold">Para iniciar este sistema
    simples:</emphasis></para>

    <para><programlisting>helm install mycluster hpcc/hpcc --version=8.6.14</programlisting></para>

    <variablelist>
      <varlistentry>
        <term>Nota:</term>

        <listitem>
          <para>O argumento --version é opcional, mas recomendado. Ele garante
          que você saiba a versão que você está instalando. Se omitido, a
          última versão não-desenvolvimento será instalada. Este exemplo usa
          8.6.14, mas você deve usar a versão que deseja.</para>
        </listitem>
      </varlistentry>
    </variablelist>

    <para>Resposta esperada:</para>

    <para><programlisting>NAME: mycluster
LAST DEPLOYED: Tue Apr 5 14:45:08 2022
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
Thank you for installing the HPCC chart version 8.6.14 using image "hpccsystems/platform-core:8.6.14"
**** WARNING: The configuration contains ephemeral planes: [dali sasha dll data mydropzone debug] ****

This chart has defined the following HPCC components:
dali.mydali
dfuserver.dfuserver
eclagent.hthor
eclagent.roxie-workunit
eclccserver.myeclccserver
eclscheduler.eclscheduler
esp.eclwatch
esp.eclservices
esp.eclqueries
esp.esdl-sandbox
esp.sql2ecl
esp.dfs
roxie.roxie
thor.thor
dali.sasha.coalescer
sasha.dfurecovery-archiver
sasha.dfuwu-archiver
sasha.file-expiry
sasha.wu-archiver</programlisting></para>

    <para>Observe o aviso sobre planos efêmeros. Isso ocorre porque essa
    implantação criou armazenamento temporário e efêmero para uso. Quando o
    cluster for desinstalado, o armazenamento não existirá mais. Isso é útil
    para um teste rápido, mas para um trabalho mais complexo, você desejará um
    armazenamento mais persistente. Isso é abordado em uma seção
    posterior.</para>

    <para><emphasis role="bold">Para verificar o status:</emphasis></para>

    <para><programlisting>kubectl get pods</programlisting></para>

    <para>Resposta esperada:</para>

    <para><programlisting>NAME                                          READY   STATUS    RESTARTS   AGE
eclqueries-7fd94d77cb-m7lmb                   1/1     Running   0          2m6s
eclservices-b57f9b7cc-bhwtm                   1/1     Running   0          2m6s
eclwatch-599fb7845-2hq54                      1/1     Running   0          2m6s
esdl-sandbox-848b865d46-9bv9r                 1/1     Running   0          2m6s
hthor-745f598795-ql9dl                        1/1     Running   0          2m6s
mydali-6b844bfcfb-jv7f6                       2/2     Running   0          2m6s
myeclccserver-75bcc4d4d-gflfs                 1/1     Running   0          2m6s
roxie-agent-1-77f696466f-tl7bb                1/1     Running   0          2m6s
roxie-agent-1-77f696466f-xzrtf                1/1     Running   0          2m6s
roxie-agent-2-6dd45b7f9d-m22wl                1/1     Running   0          2m6s
roxie-agent-2-6dd45b7f9d-xmlmk                1/1     Running   0          2m6s
roxie-toposerver-695fb9c5c7-9lnp5             1/1     Running   0          2m6s
roxie-workunit-d7446699f-rvf2z                1/1     Running   0          2m6s
sasha-dfurecovery-archiver-78c47c4db7-k9mdz   1/1     Running   0          2m6s
sasha-dfuwu-archiver-576b978cc7-b47v7         1/1     Running   0          2m6s
sasha-file-expiry-8496d87879-xct7f            1/1     Running   0          2m6s
sasha-wu-archiver-5f64594948-xjblh            1/1     Running   0          2m6s
sql2ecl-5c8c94d55-tj4td                       1/1     Running   0          2m6s
dfs-4a9f12621-jabc1                           1/1     Running   0          2m6s
thor-eclagent-6b8f564f9c-qnczz                1/1     Running   0          2m6s
thor-thoragent-56d788869f-7trxk               1/1     Running   0          2m6s</programlisting></para>

    <para><variablelist>
        <varlistentry>
          <term>Observação:</term>

          <listitem>
            <para>Pode demorar um pouco antes de todos os componentes estarem
            em execução, especialmente na primeira vez, pois as imagens do
            contêiner precisam ser baixadas do Docker Hub.</para>
          </listitem>
        </varlistentry>
      </variablelist></para>
  </sect1>

  <sect1 id="usedefault">
    <title>Acesso padrão do sistema</title>

    <para>Seu sistema agora está pronto para uso. O primeiro passo usual é
    abrir o ECL Watch.</para>

    <variablelist>
      <varlistentry>
        <term>Observação:</term>

        <listitem>
          <para>Algumas páginas no ECL Watch, como aquelas que exibem
          informações de topologia, ainda não estão totalmente funcionais no
          modo em contêiner.</para>
        </listitem>
      </varlistentry>
    </variablelist>

    <para>Use este comando para obter uma lista de serviços em execução e
    endereços IP:</para>

    <para><programlisting>kubectl get svc</programlisting></para>

    <para>Resposta esperada:</para>

    <para><programlisting>NAME                  TYPE         CLUSTER-IP      EXTERNAL-IP  PORT(S)           AGE
eclqueries            LoadBalancer 10.108.171.35   localhost    8002:31615/TCP    2m6s
eclservices           ClusterIP    10.107.121.158  &lt;none&gt;       8010/TCP          2m6s
<emphasis role="bold">eclwatch</emphasis>              LoadBalancer 10.100.81.69    <emphasis
          role="bold">localhost    8010</emphasis>:30173/TCP    2m6s
esdl-sandbox          LoadBalancer 10.100.194.33   localhost    8899:30705/TCP    2m6s
kubernetes            ClusterIP    10.96.0.1       &lt;none&gt;       443/TCP           2m6s
mydali                ClusterIP    10.102.80.158   &lt;none&gt;       7070/TCP          2m6s
roxie                 LoadBalancer 10.100.134.125  localhost    9876:30480/TCP    2m6s
roxie-toposerver      ClusterIP    None            &lt;none&gt;       9004/TCP          2m6s
sasha-dfuwu-archiver  ClusterIP    10.110.200.110  &lt;none&gt;       8877/TCP          2m6s
sasha-wu-archiver     ClusterIP    10.111.34.240   &lt;none&gt;       8877/TCP          2m6s
sql2ecl               LoadBalancer 10.107.177.180  localhost    8510:30054/TCP    2m6s
dfs                   LoadBalancer 10.100.52.9     localhost    8520:30184/TCP    2m6s</programlisting></para>

    <para>Localize o serviço ECL Watch e identifique o EXTERNAL-IP e PORTA(S)
    para eclwatch. Neste caso, é localhost:8010.</para>

    <para>Abra um navegador e acesse o ECLWatch, pressione o botão ECL e
    selecione a aba Playground.</para>

    <para>A partir daqui, você pode usar o ECL de exemplo ou inserir outras
    consultas de teste e escolher entre os clusters disponíveis para enviar
    suas workunit.</para>
  </sect1>

  <sect1 id="terminatedefault">
    <title>Encerrar (Descomissionar) o Sistema</title>

    <para>Para verificar quais helm charts estão instalados atualmente,
    execute este comando:</para>

    <para><programlisting>helm list</programlisting></para>

    <para>Isso exibe os gráficos instalados e seus nomes. Neste exemplo,
    mycluster.</para>

    <para>Para interromper os pods do HPCC Systems, use o helm para
    desinstalar:</para>

    <para><programlisting>helm uninstall mycluster</programlisting></para>

    <para>Isso interrompe o cluster, exclui os pods e, com as configurações
    padrão e os volumes persistentes, também exclui o armazenamento
    usado.</para>
  </sect1>

  <sect1 id="PVCsLocal">
    <title>Persistent Storage for a Local Deployment</title>

    <para>When running on a single-node test system such as Docker Desktop,
    the default storage class normally means that all persistent volume claims
    (PVCs) map to temporary local directories on the host machine. These are
    typically removed when the cluster is stopped. This is fine for simple
    testing but for any real application, you want persistent storage.</para>

    <para>To persist data with a Docker Desktop deployment, the first step is
    to make sure the relevant directories exist:</para>

    <orderedlist>
      <listitem>
        <para>Create data directories using a terminal interface:</para>

        <para>For Windows, use this command:</para>

        <para><programlisting>mkdir c:\hpccdata
mkdir c:\hpccdata\dalistorage
mkdir c:\hpccdata\hpcc-data
mkdir c:\hpccdata\debug
mkdir c:\hpccdata\queries
mkdir c:\hpccdata\sasha
mkdir c:\hpccdata\dropzone</programlisting></para>

        <para>For macOS, use this command:</para>

        <para><programlisting>mkdir -p /Users/myUser/hpccdata/{dalistorage,hpcc-data,debug,queries,sasha,dropzone}</programlisting></para>

        <para>For Linux, use this command:</para>

        <para><programlisting>mkdir -p ~/hpccdata/{dalistorage,hpcc-data,debug,queries,sasha,dropzone}</programlisting></para>

        <variablelist>
          <varlistentry>
            <term>Note:</term>

            <listitem>
              <para>If all of these directories do not exist, your pods may
              not start.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </listitem>

      <listitem>
        <para>Install the hpcc-localfile Helm chart.</para>

        <para>This chart creates persistent volumes based on host directories
        you created earlier.<programlisting># for a WSL2 deployment:
helm install hpcc-localfile hpcc/hpcc-localfile --set common.hostpath=/run/desktop/mnt/host/c/hpccdata

# for a Hyper-V deployment:
helm install hpcc-localfile hpcc/hpcc-localfile --set common.hostpath=/c/hpccdata

# for a macOS deployment:
helm install hpcc-localfile hpcc/hpcc-localfile --set common.hostpath=/Users/myUser/hpccdata

# for a Linux deployment:
helm install hpcc-localfile hpcc/hpcc-localfile --set common.hostpath=~/hpccdata</programlisting></para>

        <para>The <emphasis role="bold">--set common.hostpath=
        </emphasis>option specifies the base directory:</para>

        <para>The path <emphasis
        role="bold">/run/desktop/mnt/host/c/hpccdata</emphasis> provides
        access to the host file system for WSL2.</para>

        <para>The path <emphasis role="bold">/c/hpccdata</emphasis> provides
        access to the host file system for Hyper-V.</para>

        <para>The path <emphasis role="bold">/Users/myUser/hpccdata</emphasis>
        provides access to the host file system for Mac OSX.</para>

        <para>The path <emphasis role="bold">~/hpccdata</emphasis> provides
        access to the host file system for Linux.</para>

        <variablelist>
          <varlistentry>
            <term>Note:</term>

            <listitem>
              <para>The value passed to --set common-hostpath is case
              sensitive.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </listitem>

      <listitem>
        <para>Copy the output from the helm install command in the previous
        step from the word <emphasis role="bold">storage:</emphasis> to the
        end, and save it to a text file.</para>

        <para>In this example, we will call the file
        <emphasis>mystorage.yaml</emphasis>. The file should look similar to
        this:</para>

        <para><programlisting>storage:
  planes:
  - name: dali
    pvc: dali-hpcc-localfile-pvc
    prefix: "/var/lib/HPCCSystems/dalistorage"
    category: dali
  - name: dll
    pvc: dll-hpcc-localfile-pvc
    prefix: "/var/lib/HPCCSystems/queries"
    category: dll
  - name: sasha
    pvc: sasha-hpcc-localfile-pvc
    prefix: "/var/lib/HPCCSystems/sasha"
    category: sasha
  - name: debug
    pvc: debug-hpcc-localfile-pvc
    prefix: "/var/lib/HPCCSystems/debug"
    category: debug
  - name: data
    pvc: data-hpcc-localfile-pvc
    prefix: "/var/lib/HPCCSystems/hpcc-data"
    category: data
  - name: mydropzone
    pvc: mydropzone-hpcc-localfile-pvc
    prefix: "/var/lib/HPCCSystems/dropzone"
    category: lz

sasha:
  wu-archiver:
    plane: sasha
  dfuwu-archiver:
    plane: sasha</programlisting></para>
      </listitem>

      <listitem>
        <para>If you are using Docker Desktop with Hyper-V, add the shared
        data folder (in this example, C:\hpccdata) in Docker Desktop's
        settings by pressing the Add button and typing c:\hpccdata.</para>

        <para>This is <emphasis role="bold">not</emphasis> needed in a MacOS
        or WSL 2 environment.</para>

        <graphic fileref="../../images/dockerFileShare.jpg"/>
      </listitem>

      <listitem>
        <para>Finally, install the hpcc Helm chart, and provide a yaml file
        that provides the storage information created by the previous
        step.</para>

        <programlisting>helm install mycluster hpcc/hpcc --version=8.6.14 -f mystorage.yaml </programlisting>

        <variablelist>
          <varlistentry>
            <term>Note:</term>

            <listitem>
              <para>The --version argument is optional, but recommended. It
              ensures that you know which version you are installing. If
              omitted, the latest non-development version is installed. This
              example uses 8.6.14, but you should use the version you
              want.</para>
            </listitem>
          </varlistentry>
        </variablelist>
      </listitem>

      <listitem>
        <para>To test, open a browser and access ECLWatch, press the ECL
        button, and select the Playground tab, then create some data files and
        workunits by submitting to Thor some ECL code like the
        following:</para>

        <programlisting>LayoutPerson := RECORD
  UNSIGNED1 ID;
  STRING15  FirstName;
  STRING25  LastName;
END;
allPeople := DATASET([ {1,'Fred','Smith'},
                       {2,'Joe','Jones'},
                       {3,'Jane','Smith'}],LayoutPerson);
OUTPUT(allPeople,,'MyData::allPeople',THOR,OVERWRITE);
</programlisting>
      </listitem>

      <listitem>
        <para>Use the helm uninstall command to terminate your cluster, then
        restart your deployment.</para>
      </listitem>

      <listitem>
        <para>Open ECL Watch and notice your workunits and logical files are
        still there.</para>
      </listitem>
    </orderedlist>

    <para/>
  </sect1>

  <sect1 id="StoragePlanes">
    <title>Import: Storage Planes and How To Use Them</title>

    <para>Storage planes provide the flexibility to configure where the data
    is stored within a deployed HPCC Systems platform, but it doesn't directly
    address the question of how to get data onto the platform in the first
    place.</para>

    <para>Containerized platforms support importing data in two ways:</para>

    <itemizedlist>
      <listitem>
        <para>Upload a file to a Landing Zone and Import (Spray)</para>
      </listitem>

      <listitem>
        <para>Copy a file to a Storage Plane and access it directly</para>
      </listitem>
    </itemizedlist>

    <para>Beginning with version 7.12.0, new ECL syntax was added to access
    files directly from a storage plane. This is similar to the <emphasis
    role="bold">file::</emphasis> syntax used to directly read files from a
    physical machine, typically a landing zone.</para>

    <para>The new syntax is:</para>

    <para><programlisting>~plane::&lt;storage-plane-name&gt;::&lt;path&gt;::&lt;filename&gt;</programlisting>Where
    the syntax of the path and filename are the same as used with the
    <emphasis role="strong">file::</emphasis> syntax. This includes requiring
    uppercase letters to be quoted with a ^ symbol. For more details, see the
    Landing Zone Files section of the <emphasis>ECL Language
    Reference.</emphasis></para>

    <para>If you have storage planes configured as in the previous section,
    and you copy the <emphasis role="strong">originalperson</emphasis> file to
    <emphasis role="strong">C:\hpccdata\hpcc-data\tutorial</emphasis>, you can
    then reference the file using this syntax:</para>

    <para><programlisting>'~plane::data::tutorial::originalperson'</programlisting><variablelist>
        <varlistentry>
          <term>Note:</term>

          <listitem>
            <para>The <emphasis role="strong">originalperson</emphasis> file
            is available from the HPCC Systems Web site
            (https://cdn.hpccsystems.com/install/docs/3_8_0_8rc_CE/OriginalPerson).</para>
          </listitem>
        </varlistentry>
      </variablelist></para>

    <para/>

    <para/>

    <para/>
  </sect1>
</chapter>
